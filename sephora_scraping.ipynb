{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from pprint import pprint\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list of the makeup tabs we want to loop through and \n",
    "#a seperate list for the max amount of pages that are available for each tab\n",
    "\n",
    "search_list = ['foundation-makeup', 'blush', 'eyeshadow', 'eyeliner', 'moisturizer-skincare', 'face-wash-facial-cleanser', 'shampoo-sulfate-free-shampoo', 'conditioner-hair' ]\n",
    "max_page = [4, 2, 5, 3, 9, 5, 4, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foundation-makeup\n",
      "------\n",
      "blush\n",
      "------\n",
      "eyeshadow\n",
      "------\n",
      "eyeliner\n",
      "------\n",
      "moisturizer-skincare\n",
      "------\n",
      "face-wash-facial-cleanser\n",
      "------\n",
      "shampoo-sulfate-free-shampoo\n",
      "------\n",
      "conditioner-hair\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "brand_list = []\n",
    "price_list = []\n",
    "rating_list = []\n",
    "product_list = []\n",
    "link_list = []\n",
    "\n",
    "\n",
    "#searches through the tabs and pages to generate a list of all products and information\n",
    "\n",
    "for search, page in zip(search_list, max_page):\n",
    "    print(search)\n",
    "    print(\"------\")\n",
    "    \n",
    "    counter = 1\n",
    "    \n",
    "    while counter <= page:   \n",
    "        base_url = f\"https://www.sephora.com/shop/{search}?currentPage={counter}\"\n",
    "        source = requests.get(base_url).text\n",
    "        soup = BeautifulSoup(source, 'lxml')\n",
    "        \n",
    "        link = soup.find_all('a', class_='css-ix8km1')\n",
    "        for url in link:\n",
    "            link_list.append(url.get('href'))\n",
    "            \n",
    "        brands = soup.find_all('div', class_='css-1eueg40')\n",
    "        for brand in brands:\n",
    "            brand_list.append(brand.span.string)\n",
    "            \n",
    "        products = soup.find_all('span', class_='css-pelz90')\n",
    "        for product in products:\n",
    "            product_list.append(product.string)\n",
    "            \n",
    "        prices = soup.find_all('div', class_='css-68u28a')\n",
    "        for price in prices:\n",
    "            price_list.append(price.span.string)\n",
    "            \n",
    "        ratings = soup.find_all('div', class_= 'css-91sh2x')\n",
    "        for rating in ratings:\n",
    "            rating_list.append(rating.div['aria-label'])\n",
    "        \n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
